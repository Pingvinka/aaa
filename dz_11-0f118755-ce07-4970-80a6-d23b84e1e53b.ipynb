{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "5db35d05",
      "metadata": {
        "id": "5db35d05"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam, AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "cMV0vTRfAN0I",
      "metadata": {
        "id": "cMV0vTRfAN0I"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "c4bc7518",
      "metadata": {
        "id": "c4bc7518"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "train_dataset = pd.read_csv('train (1).csv').values\n",
        "test_dataset = pd.read_csv('test (1).csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "h0x_rDRpsKwN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0x_rDRpsKwN",
        "outputId": "eb914b7b-6bd5-4086-93ea-54f87ed43f78"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['den tjugofjärde 05 2049', '24-05-2049'],\n",
              "       ['15/11/77', '15-11-2077'],\n",
              "       [\"sipsa'e 02 2049\", '14-02-2049'],\n",
              "       ...,\n",
              "       ['le neuf mars 2007', '09-03-2007'],\n",
              "       ['am vier und zwanzigsten juni 2007', '24-06-2007'],\n",
              "       ['sechster juni 2007', '06-06-2007']], dtype=object)"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "76a5c735",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76a5c735",
        "outputId": "52dd0ca6-621b-43e7-ea37-6372d5b473a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MAX_LENGTH = max(map(lambda x: len(x[0]), train_dataset)) + 1\n",
        "\n",
        "MAX_LENGTH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "556ae6af",
      "metadata": {
        "id": "556ae6af"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {\n",
        "            'SOS': 0,\n",
        "            'EOS': 1\n",
        "        }\n",
        "        self.index2word = {\n",
        "            0: 'SOS',\n",
        "            1: 'EOS'\n",
        "        }\n",
        "\n",
        "    @property\n",
        "    def n_words(self) -> int:\n",
        "        return len(self.index2word)\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in list(sentence):\n",
        "            self.add_word(word)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.index2word[self.n_words] = word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "74410a56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74410a56",
        "outputId": "8ce1c5b3-c0e3-4bed-92b6-5e1469bbae84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "human 82\n",
            "iso 13\n"
          ]
        }
      ],
      "source": [
        "input_lang = Lang('human')\n",
        "output_lang = Lang('iso')\n",
        "\n",
        "for pair in train_dataset:\n",
        "    input_lang.add_sentence(pair[0])\n",
        "    output_lang.add_sentence(pair[1])\n",
        "\n",
        "print(input_lang.name, input_lang.n_words)\n",
        "print(output_lang.name, output_lang.n_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b5e4f21a",
      "metadata": {
        "id": "b5e4f21a"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "id": "nvCXodTUApeK",
      "metadata": {
        "id": "nvCXodTUApeK"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        embedded = self.embedding(x).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "id": "mzx9oOYHLpD1",
      "metadata": {
        "id": "mzx9oOYHLpD1"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.layer_norm1 = nn.LayerNorm(hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.layer_norm2 = nn.LayerNorm(hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        output = self.embedding(x).view(1, 1, -1)\n",
        "        output = self.layer_norm1(output.squeeze(0)).unsqueeze(0)\n",
        "\n",
        "        output = self.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = self.layer_norm2(output.squeeze(0)).unsqueeze(0)\n",
        "\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "id": "I3Kf0mhIWGEp",
      "metadata": {
        "id": "I3Kf0mhIWGEp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size,\n",
        "                         num_layers=num_layers,\n",
        "                         dropout=dropout if num_layers > 1 else 0)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        embedded = self.embedding(x).view(1, 1, -1)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(self.num_layers, 1, self.hidden_size, device=device)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, num_layers=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.layer_norm1 = nn.LayerNorm(hidden_size)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size,\n",
        "                         num_layers=num_layers,\n",
        "                         dropout=dropout if num_layers > 1 else 0)\n",
        "\n",
        "        self.layer_norm2 = nn.LayerNorm(hidden_size)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        output = self.embedding(x).view(1, 1, -1)\n",
        "        output = self.layer_norm1(output.squeeze(0)).unsqueeze(0)\n",
        "        output = self.dropout1(output)\n",
        "\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = self.layer_norm2(output.squeeze(0)).unsqueeze(0)\n",
        "        output = self.dropout2(output)\n",
        "\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(self.num_layers, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9503173f",
      "metadata": {},
      "source": [
        "LSTM я тоже пробовала, нооо архитектура с LSTM давала меньшую точность (хотя мне казалось, что лстм как будто бы более подходящий)\n",
        "\n",
        "Я изменяла архитектуру по-разному, увеличивала количество слоев GRU/LSTM, добавляла и линейные слои, Dropout, LayerNorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "id": "d3308116",
      "metadata": {
        "id": "d3308116"
      },
      "outputs": [],
      "source": [
        "def sentence2idx(lang, sentence):\n",
        "    return [lang.word2index[word] for word in list(sentence)]\n",
        "\n",
        "\n",
        "def sentence2tensor(lang, sentence):\n",
        "    indexes = sentence2idx(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def pair2tensor(x):\n",
        "    input_tensor = sentence2tensor(input_lang, x[0])\n",
        "    target_tensor = sentence2tensor(output_lang, x[1])\n",
        "    return input_tensor, target_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "id": "2ff20461",
      "metadata": {
        "id": "2ff20461"
      },
      "outputs": [],
      "source": [
        "def train_single(\n",
        "        input_tensor, target_tensor,\n",
        "        encoder, decoder,\n",
        "        encoder_optimizer, decoder_optimizer,\n",
        "        criterion):\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    encoder_hidden = encoder.init_hidden()\n",
        "\n",
        "    for elem in input_tensor:\n",
        "        encoder_output, encoder_hidden = encoder(elem, encoder_hidden)\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        for elem in target_tensor:\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, elem)\n",
        "            decoder_input = elem\n",
        "    else:\n",
        "        for elem in target_tensor:\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            _, topi = decoder_output.data.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "            loss += criterion(decoder_output, elem)\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / len(target_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "id": "99270fd7",
      "metadata": {
        "id": "99270fd7"
      },
      "outputs": [],
      "source": [
        "def train(encoder, decoder, n_epochs=5, print_every=100):\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "\n",
        "    encoder_optimizer = AdamW(encoder.parameters(), lr=1e-3)\n",
        "    decoder_optimizer = AdamW(decoder.parameters(), lr=1e-3)\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "    #criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        print_loss_total = 0\n",
        "\n",
        "        print(f'Epoch [{epoch + 1:02d}/{n_epochs:02d}]')\n",
        "        training_pairs = [\n",
        "            pair2tensor(x) for x in train_dataset\n",
        "        ]\n",
        "\n",
        "        for i, training_pair in enumerate(training_pairs):\n",
        "            input_tensor = training_pair[0]\n",
        "            target_tensor = training_pair[1]\n",
        "\n",
        "            loss = train_single(\n",
        "                input_tensor, target_tensor,\n",
        "                encoder, decoder,\n",
        "                encoder_optimizer, decoder_optimizer,\n",
        "                criterion\n",
        "            )\n",
        "            print_loss_total += loss\n",
        "\n",
        "            if (i + 1) % print_every == 0:\n",
        "                print_loss_avg = print_loss_total / print_every\n",
        "                print_loss_total = 0\n",
        "                print(f'Training ({i / len(training_pairs) * 100:.1f}%) loss: {print_loss_avg:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "id": "0c3f5df8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c3f5df8",
        "outputId": "ad1749b1-fca3-4830-9f69-b34b9163c932"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [01/10]\n",
            "Training (9.0%) loss: 1.7170\n",
            "Training (18.2%) loss: 1.1099\n",
            "Training (27.3%) loss: 0.7107\n",
            "Training (36.4%) loss: 0.6431\n",
            "Training (45.6%) loss: 0.6660\n",
            "Training (54.7%) loss: 0.5854\n",
            "Training (63.8%) loss: 0.5720\n",
            "Training (73.0%) loss: 0.5478\n",
            "Training (82.1%) loss: 0.5102\n",
            "Training (91.2%) loss: 0.4655\n",
            "Epoch [02/10]\n",
            "Training (9.0%) loss: 0.5612\n",
            "Training (18.2%) loss: 0.4719\n",
            "Training (27.3%) loss: 0.3896\n",
            "Training (36.4%) loss: 0.3719\n",
            "Training (45.6%) loss: 0.3208\n",
            "Training (54.7%) loss: 0.2842\n",
            "Training (63.8%) loss: 0.2775\n",
            "Training (73.0%) loss: 0.2354\n",
            "Training (82.1%) loss: 0.2188\n",
            "Training (91.2%) loss: 0.2045\n",
            "Epoch [03/10]\n",
            "Training (9.0%) loss: 0.2527\n",
            "Training (18.2%) loss: 0.1622\n",
            "Training (27.3%) loss: 0.1818\n",
            "Training (36.4%) loss: 0.1230\n",
            "Training (45.6%) loss: 0.1149\n",
            "Training (54.7%) loss: 0.1061\n",
            "Training (63.8%) loss: 0.0900\n",
            "Training (73.0%) loss: 0.0621\n",
            "Training (82.1%) loss: 0.0941\n",
            "Training (91.2%) loss: 0.0666\n",
            "Epoch [04/10]\n",
            "Training (9.0%) loss: 0.0671\n",
            "Training (18.2%) loss: 0.0647\n",
            "Training (27.3%) loss: 0.0342\n",
            "Training (36.4%) loss: 0.0421\n",
            "Training (45.6%) loss: 0.0693\n",
            "Training (54.7%) loss: 0.0478\n",
            "Training (63.8%) loss: 0.0495\n",
            "Training (73.0%) loss: 0.0361\n",
            "Training (82.1%) loss: 0.0311\n",
            "Training (91.2%) loss: 0.0288\n",
            "Epoch [05/10]\n",
            "Training (9.0%) loss: 0.0462\n",
            "Training (18.2%) loss: 0.0485\n",
            "Training (27.3%) loss: 0.0295\n",
            "Training (36.4%) loss: 0.0275\n",
            "Training (45.6%) loss: 0.0237\n",
            "Training (54.7%) loss: 0.0162\n",
            "Training (63.8%) loss: 0.0393\n",
            "Training (73.0%) loss: 0.0170\n",
            "Training (82.1%) loss: 0.0351\n",
            "Training (91.2%) loss: 0.0294\n",
            "Epoch [06/10]\n",
            "Training (9.0%) loss: 0.0418\n",
            "Training (18.2%) loss: 0.0266\n",
            "Training (27.3%) loss: 0.0169\n",
            "Training (36.4%) loss: 0.0313\n",
            "Training (45.6%) loss: 0.0213\n",
            "Training (54.7%) loss: 0.0125\n",
            "Training (63.8%) loss: 0.0354\n",
            "Training (73.0%) loss: 0.0226\n",
            "Training (82.1%) loss: 0.0130\n",
            "Training (91.2%) loss: 0.0241\n",
            "Epoch [07/10]\n",
            "Training (9.0%) loss: 0.0183\n",
            "Training (18.2%) loss: 0.0344\n",
            "Training (27.3%) loss: 0.0058\n",
            "Training (36.4%) loss: 0.0167\n",
            "Training (45.6%) loss: 0.0276\n",
            "Training (54.7%) loss: 0.0265\n",
            "Training (63.8%) loss: 0.0417\n",
            "Training (73.0%) loss: 0.0319\n",
            "Training (82.1%) loss: 0.0169\n",
            "Training (91.2%) loss: 0.0248\n",
            "Epoch [08/10]\n",
            "Training (9.0%) loss: 0.0156\n",
            "Training (18.2%) loss: 0.0035\n",
            "Training (27.3%) loss: 0.0023\n",
            "Training (36.4%) loss: 0.0030\n",
            "Training (45.6%) loss: 0.0027\n",
            "Training (54.7%) loss: 0.0056\n",
            "Training (63.8%) loss: 0.0159\n",
            "Training (73.0%) loss: 0.0123\n",
            "Training (82.1%) loss: 0.0048\n",
            "Training (91.2%) loss: 0.0343\n",
            "Epoch [09/10]\n",
            "Training (9.0%) loss: 0.0267\n",
            "Training (18.2%) loss: 0.0319\n",
            "Training (27.3%) loss: 0.0980\n",
            "Training (36.4%) loss: 0.0205\n",
            "Training (45.6%) loss: 0.0256\n",
            "Training (54.7%) loss: 0.0149\n",
            "Training (63.8%) loss: 0.0142\n",
            "Training (73.0%) loss: 0.0074\n",
            "Training (82.1%) loss: 0.0049\n",
            "Training (91.2%) loss: 0.0044\n",
            "Epoch [10/10]\n",
            "Training (9.0%) loss: 0.0093\n",
            "Training (18.2%) loss: 0.0015\n",
            "Training (27.3%) loss: 0.0035\n",
            "Training (36.4%) loss: 0.0011\n",
            "Training (45.6%) loss: 0.0024\n",
            "Training (54.7%) loss: 0.0048\n",
            "Training (63.8%) loss: 0.0035\n",
            "Training (73.0%) loss: 0.0009\n",
            "Training (82.1%) loss: 0.0009\n",
            "Training (91.2%) loss: 0.0045\n"
          ]
        }
      ],
      "source": [
        "encoder_model = Encoder(input_lang.n_words, 256).to(device)\n",
        "decoder_model = Decoder(256, output_lang.n_words).to(device)\n",
        "\n",
        "train(encoder_model, decoder_model, n_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "id": "8e2c44d0",
      "metadata": {
        "id": "8e2c44d0"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    input_tensor = sentence2tensor(input_lang, sentence)\n",
        "    encoder_hidden = encoder.init_hidden()\n",
        "\n",
        "    for elem in input_tensor:\n",
        "        encoder_output, encoder_hidden = encoder(elem, encoder_hidden)\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    decoded_words = []\n",
        "\n",
        "    for di in range(max_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "        _, topi = decoder_output.data.topk(1)\n",
        "\n",
        "        decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "        if topi.item() == EOS_token:\n",
        "            break\n",
        "\n",
        "        decoder_input = topi.squeeze().detach()\n",
        "\n",
        "    return decoded_words\n",
        "\n",
        "\n",
        "def predict_(encoder, decoder, dataset):\n",
        "    result = []\n",
        "\n",
        "    for _ in dataset:\n",
        "        result.append(evaluate(encoder, decoder, _)[:10])\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "id": "C2euTKsiW7O9",
      "metadata": {
        "id": "C2euTKsiW7O9"
      },
      "outputs": [],
      "source": [
        "test_dataset = pd.read_csv('test (1).csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "id": "b5e06197",
      "metadata": {
        "id": "b5e06197"
      },
      "outputs": [],
      "source": [
        "test_prediction = predict_(encoder_model, decoder_model, test_dataset['data'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "id": "936f704c",
      "metadata": {
        "id": "936f704c"
      },
      "outputs": [],
      "source": [
        "test_prediction = [''.join(x) for x in test_prediction]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "id": "BtI9Xj947bUL",
      "metadata": {
        "id": "BtI9Xj947bUL"
      },
      "outputs": [],
      "source": [
        "test_dataset['label'] = test_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "id": "7467be43",
      "metadata": {
        "id": "7467be43"
      },
      "outputs": [],
      "source": [
        "test_dataset[['id', 'label']].to_csv('submission.csv', index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "id": "ErMwwSo0ttEi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ErMwwSo0ttEi",
        "outputId": "b16458c9-c0be-48e8-b18f-cc59a9996649"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"test_dataset\",\n  \"rows\": 4676,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1349,\n        \"min\": 0,\n        \"max\": 4675,\n        \"num_unique_values\": 4676,\n        \"samples\": [\n          2493,\n          33,\n          3683\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4676,\n        \"samples\": [\n          \"07.08.2049\",\n          \"den tjugonionde juni 2049\",\n          \"\\u043f\\u0435\\u0440\\u0432\\u043e\\u0433\\u043e 04 2007\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1092,\n        \"samples\": [\n          \"01-10-2007\",\n          \"25-07-2049\",\n          \"22-08-2077\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "test_dataset"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-29dce810-45e5-469e-b3fa-f94d0f216ebf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>24 января 2007</td>\n",
              "      <td>24-01-2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>le six mars 2049</td>\n",
              "      <td>06-03-2049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>le dix 05 2077</td>\n",
              "      <td>10-05-2077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>27 июня 2049</td>\n",
              "      <td>27-06-2049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>08 гыйнварда 2077</td>\n",
              "      <td>08-01-2077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4671</th>\n",
              "      <td>4671</td>\n",
              "      <td>am fünfzehnten januar 2049</td>\n",
              "      <td>15-01-2049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4672</th>\n",
              "      <td>4672</td>\n",
              "      <td>тугызынчы 05 2049</td>\n",
              "      <td>09-05-2049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4673</th>\n",
              "      <td>4673</td>\n",
              "      <td>der achzehnte 02 2007</td>\n",
              "      <td>18-02-2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4674</th>\n",
              "      <td>4674</td>\n",
              "      <td>vierzehnter 12 2049</td>\n",
              "      <td>14-12-2049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4675</th>\n",
              "      <td>4675</td>\n",
              "      <td>20/01/77</td>\n",
              "      <td>20-01-2077</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4676 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29dce810-45e5-469e-b3fa-f94d0f216ebf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29dce810-45e5-469e-b3fa-f94d0f216ebf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29dce810-45e5-469e-b3fa-f94d0f216ebf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-639bbe0c-cd62-4557-a62e-c315403463f7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-639bbe0c-cd62-4557-a62e-c315403463f7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-639bbe0c-cd62-4557-a62e-c315403463f7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        id                        data       label\n",
              "0        0              24 января 2007  24-01-2007\n",
              "1        1            le six mars 2049  06-03-2049\n",
              "2        2              le dix 05 2077  10-05-2077\n",
              "3        3                27 июня 2049  27-06-2049\n",
              "4        4           08 гыйнварда 2077  08-01-2077\n",
              "...    ...                         ...         ...\n",
              "4671  4671  am fünfzehnten januar 2049  15-01-2049\n",
              "4672  4672           тугызынчы 05 2049  09-05-2049\n",
              "4673  4673       der achzehnte 02 2007  18-02-2007\n",
              "4674  4674         vierzehnter 12 2049  14-12-2049\n",
              "4675  4675                    20/01/77  20-01-2077\n",
              "\n",
              "[4676 rows x 3 columns]"
            ]
          },
          "execution_count": 264,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dataset"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7",
      "language": "python",
      "name": "3.7"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
